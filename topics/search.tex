\subsection{Search}

\Blue{Definition} by doing action $a$ from state $s$, we deterministically
arrive in state $\text{Succ}(s,a)$. Goal: determine a sequence of actions
between $s_{\text{start}}$ and an end state on a minumum cost path.
\begin{itemize}
    \item $S_\text{start}$, $\text{IsEnd}(s)$, $\text{Actions}(s)$
    \item $\text{Cost}(s,a)$: action cost
    \item $\text{Succ}(s,a)$ of state $s$ after action $a$
\end{itemize}

\Red{State} a summary of all past actions sufficient to choose future actions optimally.

\begin{itemize}
    \item \textbf{Explored}: states for which the optimal path has been found
    \item \textbf{Frontier}: states seen for which we are still figuring out how to get there with the cheapest cost
    \item \textbf{Unexplored}: states not yet seen
\end{itemize}

\subsubsection{Tree search}

\Red{Algorithms} $b$: \# actions per state; $d$: solution depth, and $D$:
maximum depth.
\begin{tabular}{|c|c|c|c|} 
    \hline
    \textbf{Algo}  & \textbf{Cost} & \textbf{Space} & \textbf{Time} \\
    \hline
    Backtracting & any & $O(D)$ & $O(b^D)$ \\ 
    \hline
    BFS & $c \ge 0$ & $O(b^d)$ & $O(b^d)$ \\
    \hline
    DFS & $0$ & $O(D)$ & $O(b^D)$ \\
    \hline
    DFS-ID & $c \ge 0$ & $O(d)$ & $O(b^d)$ \\
    \hline
\end{tabular}

\subsubsection{Graph search}

\Blue{Dynamic programming (DP)} a Backtracting search algorithm that only works
for acyclic graphs.
$\text{FutureCost}(s) = \min_{a\in A(s)}\left[\text{Cost}(s,a) + \text{FutureCost}(\text{Succ}(s,a))\right]$
or $0$ if at end state.

\Green{Uniform cost search (UCS)} explores states $s$ in increasing order of
PastCost$(s)$, assuming \textbf{all action costs are non-negative}. Adding a
positive constant to all costs would make a \emph{different} problem.

\Red{Correctness theorem} when a state $s$ is popped from the frontier and moved
to explored, its priority being $\text{PastCost}(s)$ is the minimum cost path
$S_\text{start} \rightarrow s$.

\Red{Algorithms} $N$: \# total states; $n$ \# states explored before $s_{end}$;
assume const \# actions per state.

\begin{tabular}{|c|c|c|c|} 
    \hline
    \textbf{Algo} & \textbf{Cycle?} & \textbf{Cost} & \textbf{Time/space} \\
    \hline
    DP & No! & any & $O(N)$ \\ 
    \hline
    UCS & Ok & $c \ge 0$ & $O(n \log(n))$ \\
    \hline
\end{tabular}

\Green{Heuristic func} each $h(s)$ estimates $\text{FutureCost}(s)$ (cost of $s
\rightarrow s_{\text{end}}$ path).
\fbox{$h(s) \le \text{FutureCost}(s)$ $\Rightarrow$ $h(s)$ \textcolor{Green}{admissible}}
\fbox{$h(s)$ consistent $\Rightarrow$ $h(s)$ \textcolor{Green}{admissible}}

\Red{$A\star$ search} \Hint{first modify path costs and then run UCS}:
\fbox{$\text{Cost}'(s,a) = \text{Cost}(s,a) + h(\text{Succ}(s,a)) - h(s)$}

\Blue{Consistency} $h$ is consistent if
\fbox{$h(s_{\text{end}}) = 0$} \underline{\&\&}
\fbox{$\forall s,a$ $h(s) \le \text{Cost}(s,a) + h(\text{Succ}(s,a))$}
(if not true, modified path cost can be negative!).
If multiple heuristics are consistent, \textbf{max of them} is better:
guaranteed consistency and the largest possible heuristic value leads to fewer
states visited overall.

\Red{Correctness} $h$ is consistent $\Rightarrow$ $A\star$ returns the min cost path.

\Red{Efficiency} $A\star$ explores all states satisfying:
\fbox{$\text{PastCost}(s) \le \text{PastCost}(s_{\text{end}}) - h(s)$}

\Green{Relaxed search problem} search problem $P$ with $\text{Cost}$ relaxed
into $P_\text{rel}$ with $\text{Cost}_\text{rel}$, where
\fbox{$\text{Cost}_\text{rel}(s,a) \le \text{Cost}(s,a)$}

\Red{Relaxed heuristic} $h(s) = \text{FutureCost}_\text{rel}(s)$ as the min cost
path $s \rightarrow s_{\text{end}}$ in the graph of
$\text{Cost}_\text{rel}(s,a)$.
\fbox{$h(s) = \text{FutureCost}_\text{rel}(s) \Rightarrow h(s)$ consistent}

\Green{Choosing heuristic} balance two aspects:
\begin{itemize}
    \item Easy to compute $h(s) = \text{FutureCost}_\text{rel}(s)$.
    \item $h(s)$ should be close to $\text{FutureCost}$, thus not removing too
        many constraints.
\end{itemize}